【已解决】
975/1000
平均奖励值为：94.3133

100轮测试奖励值：93.46712

self.algo_name = algo_name         # 算法名称
        self.env_name = env_name           # 环境名称
        self.device = device               # 训练所用设备
        self.train_eps = 1000               # 训练的回合数
        self.test_eps = 100                 # 测试的回合数
        self.gamma = 0.99                  # 折扣因子
        self.max_step = 100000             # 单回合最大步数
        self.critic_lr = 1e-3              # Critic网络的学习率
        self.actor_lr = 1e-4               # Actor网络的学习率
        self.memory_capacity = 1000000     # 经验回放的容量
        self.batch_size = 64               # mini-batch SGD中的批量大小
        # self.target_update = 2             # 目标网络的更新频率
        self.hidden1_dim = 256             # 网络隐藏层1维度
        self.hidden2_dim = 128             # 网络隐藏层2维度
        self.soft_tau = 1e-2               # 软更新参数
        self.ep_r = 10                    # 计算最后10轮平均奖励，确定是否保存模型
        self.seed = 666                    # 设置随机种子
        self.epsilon_start = 0.99             # e-greedy策略中初始epsilon
        self.epsilon_end = 0.01               # e-greedy策略中的终止epsilon
        self.epsilon_decay = 50000         # e-greedy策略中epsilon的衰减率

OUActionNoise
mu, sigma=0.3, theta=0.4, dt=1e-2, x0=None